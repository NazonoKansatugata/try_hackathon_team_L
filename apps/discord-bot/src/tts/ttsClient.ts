import { VoiceProfile } from '../types/index.js';
import { Readable } from 'stream';
import { execFile } from 'child_process';
import { createReadStream, unlinkSync } from 'fs';
import { resolve } from 'path';
import { promisify } from 'util';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const execFileAsync = promisify(execFile);
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

interface Qwen3Response {
  status: string;
  output_path?: string;
  sample_rate?: number;
  duration_ms?: number;
  error?: string;
}

/**
 * Qwen3-TTS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
 * Python qwen-tts ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆ
 */
export class TTSClient {
  private wrapperPyPath: string;

  constructor() {
    this.wrapperPyPath = resolve(__dirname, 'qwen3-wrapper.py');
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
   * @param text èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @param voiceProfile éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã€è¨€èªï¼‰
   * @returns éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ 
   */
  async textToSpeech(text: string, voiceProfile: VoiceProfile): Promise<Readable> {
    const textTruncated = text.substring(0, 50);
    console.log(`ğŸ¤ TTSç”Ÿæˆé–‹å§‹ [${voiceProfile.speaker}]: "${textTruncated}${text.length > 50 ? '...' : ''}"`);
    
    try {
      // Pythonãƒ©ãƒƒãƒ‘ãƒ¼ã‚’å®Ÿè¡Œï¼ˆoutput_pathã¯çœç•¥ã—ã¦Pythonå´ã§tempfileè‡ªå‹•ç”Ÿæˆï¼‰
      const args = [
        this.wrapperPyPath,
        text,
        voiceProfile.speaker,
        voiceProfile.language || 'Japanese',
        voiceProfile.instruct || 'none',
      ];
      const { stdout, stderr } = await execFileAsync('python', args);

      // æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’è¡¨ç¤ºï¼ˆé€²æ—ãƒ­ã‚°ï¼‰
      if (stderr) {
        console.log(`ğŸ“Œ TTSå‡ºåŠ›: ${stderr.trim()}`);
      }

      // JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆstdoutã®æœ€å¾Œã®è¡Œã‹ã‚‰å–å¾—ï¼‰
      const lines = stdout.trim().split('\n');
      const jsonLine = lines[lines.length - 1];
      const result: Qwen3Response = JSON.parse(jsonLine);
      
      if (result.status !== 'success') {
        throw new Error(`TTS Error: ${result.error}`);
      }

      console.log(`âœ… TTSç”Ÿæˆå®Œäº† (${result.duration_ms}ms)`);

      // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§è¿”ã™
      // å®Œäº†å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      const stream = createReadStream(result.output_path!);
      stream.on('end', () => {
        try {
          unlinkSync(result.output_path!);
          console.log(`ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: ${result.output_path!}`);
        } catch (err) {
          console.warn(`âš ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: ${err}`);
        }
      });

      return stream;
    } catch (error) {
      console.error('âŒ TTSç”Ÿæˆã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç„¡éŸ³ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
   */
  async generateSilence(duration: number = 1000): Promise<Readable> {
    console.log(`ğŸ”‡ ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ (${duration}ms)`);
    
    // 48kHz, 1ch, 16bitã®PCMãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    const sampleRate = 48000;
    const channels = 1;
    const bytesPerSample = 2;
    const samples = Math.floor((duration / 1000) * sampleRate);
    const bufferSize = samples * channels * bytesPerSample;
    
    const silenceBuffer = Buffer.alloc(bufferSize, 0);
    
    return Readable.from(silenceBuffer);
  }

  /**
   * ãƒ¢ãƒ‡ãƒ«ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ
   */
  async testConnection(): Promise<boolean> {
    try {
      console.log('ğŸ” Qwen3-TTSãƒ¢ãƒ‡ãƒ«ã®æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...');
      
      // ãƒ€ãƒŸãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã§å®Ÿè¡Œ
      const stream = await this.textToSpeech('ãƒ†ã‚¹ãƒˆ', {
        speaker: 'Vivian',
        language: 'Japanese',
      });
      
      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒç”Ÿæˆã•ã‚ŒãŸã‚‰æˆåŠŸ
      stream.destroy(); // ã™ãã«ç ´æ£„
      console.log('âœ… Qwen3-TTSæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ');
      return true;
      
    } catch (error) {
      console.error('âŒ Qwen3-TTSæ¥ç¶šãƒ†ã‚¹ãƒˆ ã‚¨ãƒ©ãƒ¼:', error);
      return false;
    }
  }
}
