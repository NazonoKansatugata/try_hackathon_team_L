#!/usr/bin/env python3
"""
Qwen3-TTS Python Wrapper
TypeScriptã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼
"""
import sys
import json
import torch
import numpy as np
import tempfile
import os
from pathlib import Path
from qwen_tts import Qwen3TTSModel

# è­¦å‘Šã‚’ç„¡åŠ¹åŒ–
import warnings
warnings.filterwarnings("ignore")


def generate_speech(text: str, speaker: str, language: str = "Japanese", instruct: str = None, output_path: str = None):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆ
    
    Args:
        text: è©±ã•ã›ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        speaker: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å (Vivian, Serena, Ryan ãªã©)
        language: è¨€èª ("Japanese", "English", "Auto" ãªã©)
        instruct: å£°ã®æŒ‡ç¤ºï¼ˆè©±ã—æ–¹ã®ç‰¹å¾´ã‚’æŒ‡å®šï¼‰
        output_path: å‡ºåŠ›WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        print(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...", file=sys.stderr)
        model = Qwen3TTSModel.from_pretrained(
            "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
            device_map="cpu",
            dtype=torch.float32,
        )
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†", file=sys.stderr)
        
        # éŸ³å£°ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        generate_params = {
            "text": text,
            "language": language,
            "speaker": speaker,
        }
        if instruct:
            generate_params["instruct"] = instruct
        
        # éŸ³å£°ç”Ÿæˆ
        print(f"ğŸ¤ éŸ³å£°ç”Ÿæˆä¸­: {text[:50]}...", file=sys.stderr)
        wavs, sr = model.generate_custom_voice(**generate_params)
        print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†", file=sys.stderr)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆWindowså¯¾å¿œã€scipyä½¿ç”¨ï¼‰
        if output_path is None:
            fd, output_path = tempfile.mkstemp(suffix='.wav', prefix='qwen3_tts_')
            os.close(fd)
        
        # scipy.io.wavfile ã‚’ä½¿ç”¨ï¼ˆSoXä¸è¦ï¼‰
        from scipy.io import wavfile
        # float32 â†’ int16 ã«å¤‰æ›
        audio_int16 = np.int16(wavs[0] * 32767)
        wavfile.write(output_path, sr, audio_int16)
        print(f"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}", file=sys.stderr)
        
        # ãƒ‘ã‚¹ã‚’è¿”ã™
        result = {
            "status": "success",
            "output_path": output_path,
            "sample_rate": int(sr),
            "duration_ms": int(len(wavs[0]) / sr * 1000)
        }
        print(json.dumps(result))
        
    except Exception as e:
        error_result = {
            "status": "error",
            "error": str(e)
        }
        print(json.dumps(error_result), file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print(json.dumps({"status": "error", "error": "Usage: text speaker [language] [instruct] [output_path]"}), file=sys.stderr)
        sys.exit(1)
    
    text = sys.argv[1]
    speaker = sys.argv[2]
    language = sys.argv[3] if len(sys.argv) > 3 else "Japanese"
    instruct = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4] != "none" else None
    output_path = sys.argv[5] if len(sys.argv) > 5 else None
    
    generate_speech(text, speaker, language, instruct, output_path)
